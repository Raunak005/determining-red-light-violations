{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from ipynb.fs.full.ColourSpaceConversionUtil import *\n",
    "\n",
    "def maintainAspectRatioWhileResizing(originalImage, width, height, pixelAreaRelation):\n",
    "    \n",
    "    # The dimensions of the image are initialized and the shape of the image is determined\n",
    "    imageDimension = None\n",
    "    (h, w) = originalImage.shape[:2]\n",
    "\n",
    "    #The original image is returned if the resizing width and height are not provided at the time of invoking\n",
    "    if width is None and height is None:\n",
    "        return originalImage\n",
    "    \n",
    "    if width is None:\n",
    "        #Calculate the aspect ratio of the resized height to the original height if the resized width is none (or not provided)\n",
    "        ratio = height / float(h)\n",
    "        #Calculate the resized image dimension\n",
    "        imageDimension = (int(w * ratio), height)\n",
    "    else:\n",
    "        #Calculate the aspect ratio of the resized width to the original width if the resized height is none (or not provided)\n",
    "        ratio = width / float(w)\n",
    "        #Calculate the resized image dimension\n",
    "        imageDimension = (width, int(h * ratio))\n",
    "\n",
    "    #The original image is now resized and returned based on the calculated image dimensions while maintaining the aspect ratio\n",
    "    return cv2.resize(originalImage, imageDimension, interpolation=pixelAreaRelation)\n",
    "\n",
    "\n",
    "def probabilisticHoughLineTransform(rgbImage):\n",
    "    \n",
    "    #Purpose: Grayscale image is preferred over a colour image in Hough Transform\n",
    "    grayscale_image=colourRGBToGrayConversion(rgbImage)\n",
    "    \n",
    "    \n",
    "    #Edge Detection using Canny Edge Detector\n",
    "    #Arg1 is the grayscale image \n",
    "    #Arg2 is the first threshold\n",
    "    #Arg3 is the second threshold\n",
    "    #Arg4 is the aperture size\n",
    "    edges = cv2.Canny(grayscale_image, 40, 55, apertureSize=3)\n",
    "    \n",
    "    #Mapping the edge points to the Hough space using the Probabilistic Hough Line transformation algorithm that is available in OpenCV\n",
    "    #Arg1 is the edge detected image \n",
    "    #Arg2 is the rho value which is the distance resolution of the accumulator (in pixels)\n",
    "    #Arg3 is the theta value which is the angle resolution of the accumulator (in radians)\n",
    "    #Arg4 is the accumulator's threshold parameter which implies that lines whose value is greater than the mentioned threshold value are only returned\n",
    "    #Arg5 is the minimum length of the detected line. Lines less than the minimum length shall be ignored.\n",
    "    #Arg6 is the maximum permissible gap between the line segments so that each line segment is considered as a single line\n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,180,minLineLength=50,maxLineGap=50)\n",
    "    \n",
    "    #Each line is represented by two points - P1(x1,y1) and P2(x2,y2)\n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2 = line[0]\n",
    "        \n",
    "        #Arg1 is the color image\n",
    "        #Arg2 is the Cartesian co-ordinate of point 1 i.e., P1\n",
    "        #Arg3 is the Cartesian co-ordinate of point 2 i.e., P2\n",
    "        #Arg4 is the colour (i.e., RGB value)\n",
    "        #Arg5 is the thickness of the line\n",
    "        cv2.line(rgbImage,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "\n",
    "def region_of_interest(image, roiVertices):\n",
    "    \n",
    "    # Creating a mask using numpy\n",
    "    mask = np.zeros_like(image)\n",
    "    \n",
    "    # Setting mask colour\n",
    "    matchMaskColor = 255\n",
    "    \n",
    "    # Applying the mask and the region of interest vertices to the image\n",
    "    cv2.fillPoly(mask, roiVertices, matchMaskColor)\n",
    "    \n",
    "    # Performing bitwise AND to obtain the masked image\n",
    "    maskedImage = cv2.bitwise_and(image, mask)\n",
    "    \n",
    "    return maskedImage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
